{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook:\n",
    "- explores the dataset to gain a basic understanding\n",
    "- filters out unwanted instances e.g. empty or duplicate texts\n",
    "- samples 2000 instances to label manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the dataset\n",
    "- Obtain basic statistics and characteristics of the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# comments scraped: 251623\n"
     ]
    }
   ],
   "source": [
    "# Load in the data from CSV\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "allComments = pd.read_csv(\"data/comments.csv\", usecols=['document_id', 'comment', 'has_attachments'])\n",
    "allComments['comment'] = allComments['comment'].map(lambda x: re.sub(\"(\\r|\\n)\", \" \", x))\n",
    "print(\"# comments scraped:\", allComments.shape[0])\n",
    "\n",
    "# allComments = allComments.drop_duplicates(subset = ['comment'])\n",
    "# print(\"# comments with duplicates removed:\", allComments.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91105     I am appalled that our treasured National monu...\n",
       "198592    Please keep these monuments free from developm...\n",
       "94494     I am appalled that our treasured National monu...\n",
       "126505    Dear Secretary Ryan Zinke,  I am writing in su...\n",
       "17804                       Please Write Your Comment Here:\n",
       "210437    Dear Secretary Ryan Zinke,  As a supporter of ...\n",
       "95014     Dear Secretary Ryan Zinke,  I moved to Souther...\n",
       "246553    I strongly urge you to continue to protect all...\n",
       "50024     I am opposed to any alterations to Mojave Trai...\n",
       "198714    Dear Secretary Ryan Zinke,  As an avid outdoor...\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample 10 comments to veiw \n",
    "\n",
    "allComments.sample(10).comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split texts into sentences\n",
    "# Ref: https://stackoverflow.com/a/31505798\n",
    "\n",
    "import re\n",
    "\n",
    "caps = \"([A-Z])\"\n",
    "digits = \"([0-9])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\n",
    "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "websites = \"[.](com|net|org|io|gov)\"\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    '''\n",
    "    Function to break text (astring) into sentences (a list of strings).\n",
    "    '''\n",
    "    \n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "    text = re.sub(\"\\s\" + caps + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(digits + \"[.]\" + digits,\"\\\\1<prd>\\\\2\",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(caps + \"[.]\" + caps + \"[.]\" + caps + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(caps + \"[.]\" + caps + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + caps + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = [s.strip() for s in sentences if len(s.strip())>1]\n",
    "    return sentences\n",
    "\n",
    "allComments['sentences'] = allComments['comment'].map(lambda x: split_into_sentences(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sentences: 1909473\n",
      "# unique sentences: 558473\n",
      "\n",
      "10 most common sentences:\n",
      "1 Please make sure you side with the people who supp... 58821\n",
      "2 Every single one of our parks, monuments and cultu... 58764\n",
      "3 It is your job as the Secretary of the Dept.... 54012\n",
      "4 Hear me, and the overwhelming number of people who... 54011\n",
      "5 of Interior to protect and safeguard our national ... 54008\n",
      "6 I am adamantly opposed to any effort to eliminate ... 54008\n",
      "7 Five Tribal nations, Hopi, Navajo, Uintah and Oura... 42050\n",
      "8 Now the Bears Ears Inter-Tribal Coalition is worki... 42046\n",
      "9 The short review you are undertaking makes a mocke... 42044\n",
      "10 I am appalled that our treasured National monument... 42043\n"
     ]
    }
   ],
   "source": [
    "# Output some statistics about the corpus\n",
    "\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "\n",
    "sentences = [s for sublist in allComments['sentences'] for s in sublist]\n",
    "print(\"# sentences:\", len(sentences))\n",
    "\n",
    "frequency = defaultdict(int)\n",
    "for sent_list in allComments['sentences']:\n",
    "    for sent in sent_list:\n",
    "        frequency[sent] += 1\n",
    "\n",
    "uniqueSentences = list(frequency.keys())\n",
    "print(\"# unique sentences:\", len(uniqueSentences))\n",
    "print()\n",
    "\n",
    "sorted_frequency_list = sorted(frequency.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print(\"10 most common sentences:\")\n",
    "for index, row in enumerate(sorted_frequency_list[:10]):\n",
    "    print(index+1, row[0][:50]+\"...\", row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the sample comments and sentence frequencies, it is clear that a large portion of comments were submitted in templates. We need to identify those template comments so that when we sample comments to label (for model training) we do not have duplicate or overly similar text. We want to prevent words used in templates from biasing our feature weights. One simple way to filter out template comments is compare the first two sentences in the text and then remove comments whose starting two sentences have been seen in previous comments. The reasoning is that two posters are unlikely to have written the same words if they didn't come from a template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out comments\n",
    "- Remove empty comments\n",
    "- Remove comments with attachments\n",
    "- Remove duplicate and template comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# comments with empty comments removed: 250888\n"
     ]
    }
   ],
   "source": [
    "# Remove empty comments whose sentence count is zero \n",
    "# or whose text contains only the official template lines\n",
    "# i.e. \"Dear Secretary Ryan Zinke,\" and/or \"Leave your personal comment here...\"\n",
    "\n",
    "def hasContent(sentences):\n",
    "    if len(sentences) == 0:\n",
    "        return False\n",
    "    if sentences[0].find('Leave your personal comment here') != -1 \\\n",
    "    or (len(sentences) == 2 and len(sentences[0]) < 30 and \\\n",
    "        sentences[0].find('Dear Secretary Ryan Zinke,') != -1):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "allComments = allComments[allComments['sentences'].map(hasContent)]\n",
    "print(\"# comments with empty comments removed:\", allComments.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# comments without attachments: 246733\n"
     ]
    }
   ],
   "source": [
    "# Remove comments with attachments\n",
    "\n",
    "allComments = allComments[allComments['has_attachments'] == False]\n",
    "print(\"# comments without attachments:\", allComments.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>has_attachments</th>\n",
       "      <th>comment</th>\n",
       "      <th>sentences</th>\n",
       "      <th>first_two_sents</th>\n",
       "      <th>duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22978</th>\n",
       "      <td>DOI-2017-0002-119884</td>\n",
       "      <td>False</td>\n",
       "      <td>Dear Secretary Ryan Zinke, You hunt. So let us...</td>\n",
       "      <td>[Dear Secretary Ryan Zinke, You hunt., So let ...</td>\n",
       "      <td>dear secretary ryan zinke you hunt so let us c...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110621</th>\n",
       "      <td>DOI-2017-0002-2343</td>\n",
       "      <td>False</td>\n",
       "      <td>Sec. Zinke contradicted himself in the press r...</td>\n",
       "      <td>[Sec., Zinke contradicted himself in the press...</td>\n",
       "      <td>sec zinke contradicted himself in the press re...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35298</th>\n",
       "      <td>DOI-2017-0002-131398</td>\n",
       "      <td>False</td>\n",
       "      <td>Please leave the national monuments alone as t...</td>\n",
       "      <td>[Please leave the national monuments alone as ...</td>\n",
       "      <td>please leave the national monuments alone as t...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8469</th>\n",
       "      <td>DOI-2017-0002-106734</td>\n",
       "      <td>False</td>\n",
       "      <td>Dear Secretary Ryan Zinke,  I've grown up and ...</td>\n",
       "      <td>[Dear Secretary Ryan Zinke,  I've grown up and...</td>\n",
       "      <td>dear secretary ryan zinke ve grown up and spen...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74367</th>\n",
       "      <td>DOI-2017-0002-176761</td>\n",
       "      <td>False</td>\n",
       "      <td>I am appalled that our treasured national park...</td>\n",
       "      <td>[I am appalled that our treasured national par...</td>\n",
       "      <td>am appalled that our treasured national parks ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 document_id has_attachments  \\\n",
       "22978   DOI-2017-0002-119884           False   \n",
       "110621    DOI-2017-0002-2343           False   \n",
       "35298   DOI-2017-0002-131398           False   \n",
       "8469    DOI-2017-0002-106734           False   \n",
       "74367   DOI-2017-0002-176761           False   \n",
       "\n",
       "                                                  comment  \\\n",
       "22978   Dear Secretary Ryan Zinke, You hunt. So let us...   \n",
       "110621  Sec. Zinke contradicted himself in the press r...   \n",
       "35298   Please leave the national monuments alone as t...   \n",
       "8469    Dear Secretary Ryan Zinke,  I've grown up and ...   \n",
       "74367   I am appalled that our treasured national park...   \n",
       "\n",
       "                                                sentences  \\\n",
       "22978   [Dear Secretary Ryan Zinke, You hunt., So let ...   \n",
       "110621  [Sec., Zinke contradicted himself in the press...   \n",
       "35298   [Please leave the national monuments alone as ...   \n",
       "8469    [Dear Secretary Ryan Zinke,  I've grown up and...   \n",
       "74367   [I am appalled that our treasured national par...   \n",
       "\n",
       "                                          first_two_sents duplicate  \n",
       "22978   dear secretary ryan zinke you hunt so let us c...     False  \n",
       "110621  sec zinke contradicted himself in the press re...     False  \n",
       "35298   please leave the national monuments alone as t...     False  \n",
       "8469    dear secretary ryan zinke ve grown up and spen...     False  \n",
       "74367   am appalled that our treasured national parks ...      True  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mark duplicates: considering that there are minor variations within the same template \n",
    "# (e.g. punctuations and spaces), use gensim's built-in function simple_preprocess() \n",
    "# to lowercase and tokenize sentences.\n",
    "\n",
    "import gensim\n",
    "\n",
    "def tokenize(text, minLength=3):\n",
    "    return gensim.utils.simple_preprocess(text, deacc=True, min_len=minLength)\n",
    "\n",
    "allComments['first_two_sents'] = allComments['sentences'].map(lambda x: \" \".join([\" \".join(tokenize(sent,2)) for sent in x[:2]]))\n",
    "allComments['duplicate'] = allComments.duplicated(subset=['first_two_sents'], keep=False)\n",
    "allComments.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write to file\n",
    "\n",
    "allComments[['document_id','comment','duplicate']].to_csv('data/comments-cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample data \n",
    "- randomly sample 2000 instances\n",
    "- output to file for manual labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# rather unique comments: 85285\n"
     ]
    }
   ],
   "source": [
    "# To avoid repeating training examples, drop duplicate comments whose first two sentences are identical\n",
    "\n",
    "uniqueComments = allComments.drop_duplicates(subset=['first_two_sents'])\n",
    "print(\"# rather unique comments:\", uniqueComments.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output 2000 comments to CSV for manual labelling\n",
    "\n",
    "comments_to_label = uniqueComments[['document_id', 'comment']].sample(2000)\n",
    "comments_to_label.to_csv('data/comments-to-label.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output unique comments for later use\n",
    "\n",
    "uniqueComments[['document_id', 'comment']].to_csv('data/uniqueComments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
