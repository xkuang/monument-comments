{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow of data preparation:\n",
    "- extract a text stream from (raw) data\n",
    "- clean up texts through stopword removal and lemmatization\n",
    "- break sanitized text into words and collocations (features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>document_id</th>\n",
       "      <th>tracking_number</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>retrieved</th>\n",
       "      <th>has_attachments</th>\n",
       "      <th>comment</th>\n",
       "      <th>document_url</th>\n",
       "      <th>ID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>labelled_by</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>DOI-2017-0002-0002</td>\n",
       "      <td>1k1-8wbs-ucnh</td>\n",
       "      <td>2017-05-11</td>\n",
       "      <td>2017-05-27 01:43:49.443154</td>\n",
       "      <td>False</td>\n",
       "      <td>Our national monuments are a national treasure...</td>\n",
       "      <td>https://www.regulations.gov/document?D=DOI-201...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DOI-2017-0002-0003</td>\n",
       "      <td>1k1-8wbs-1cws</td>\n",
       "      <td>2017-05-11</td>\n",
       "      <td>2017-05-26 21:35:25.550530</td>\n",
       "      <td>False</td>\n",
       "      <td>1.We do not want National Monument protection ...</td>\n",
       "      <td>https://www.regulations.gov/document?D=DOI-201...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>DOI-2017-0002-0004</td>\n",
       "      <td>1k1-8wbs-oj39</td>\n",
       "      <td>2017-05-11</td>\n",
       "      <td>2017-05-30 10:14:25.162305</td>\n",
       "      <td>False</td>\n",
       "      <td>The monuments must be preserved. the precedent...</td>\n",
       "      <td>https://www.regulations.gov/document?D=DOI-201...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DOI-2017-0002-0005</td>\n",
       "      <td>1k1-8wbs-9rjp</td>\n",
       "      <td>2017-05-11</td>\n",
       "      <td>2017-05-30 10:14:31.861017</td>\n",
       "      <td>False</td>\n",
       "      <td>My name is Ryan Erik Benally and I'm from Mont...</td>\n",
       "      <td>https://www.regulations.gov/document?D=DOI-201...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>DOI-2017-0002-0006</td>\n",
       "      <td>1k1-8wbs-umhr</td>\n",
       "      <td>2017-05-11</td>\n",
       "      <td>2017-05-27 04:10:25.339717</td>\n",
       "      <td>False</td>\n",
       "      <td>all protections and preservations for the enti...</td>\n",
       "      <td>https://www.regulations.gov/document?D=DOI-201...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         document_id tracking_number date_posted  \\\n",
       "0           0  DOI-2017-0002-0002   1k1-8wbs-ucnh  2017-05-11   \n",
       "1           1  DOI-2017-0002-0003   1k1-8wbs-1cws  2017-05-11   \n",
       "2           2  DOI-2017-0002-0004   1k1-8wbs-oj39  2017-05-11   \n",
       "3           3  DOI-2017-0002-0005   1k1-8wbs-9rjp  2017-05-11   \n",
       "4           4  DOI-2017-0002-0006   1k1-8wbs-umhr  2017-05-11   \n",
       "\n",
       "                    retrieved has_attachments  \\\n",
       "0  2017-05-27 01:43:49.443154           False   \n",
       "1  2017-05-26 21:35:25.550530           False   \n",
       "2  2017-05-30 10:14:25.162305           False   \n",
       "3  2017-05-30 10:14:31.861017           False   \n",
       "4  2017-05-27 04:10:25.339717           False   \n",
       "\n",
       "                                             comment  \\\n",
       "0  Our national monuments are a national treasure...   \n",
       "1  1.We do not want National Monument protection ...   \n",
       "2  The monuments must be preserved. the precedent...   \n",
       "3  My name is Ryan Erik Benally and I'm from Mont...   \n",
       "4  all protections and preservations for the enti...   \n",
       "\n",
       "                                        document_url   ID Sentiment  \\\n",
       "0  https://www.regulations.gov/document?D=DOI-201...  NaN       NaN   \n",
       "1  https://www.regulations.gov/document?D=DOI-201...  NaN       NaN   \n",
       "2  https://www.regulations.gov/document?D=DOI-201...  NaN       NaN   \n",
       "3  https://www.regulations.gov/document?D=DOI-201...  NaN       NaN   \n",
       "4  https://www.regulations.gov/document?D=DOI-201...  NaN       NaN   \n",
       "\n",
       "  labelled_by  pos  neg  \n",
       "0         NaN    0    0  \n",
       "1         NaN    0    0  \n",
       "2         NaN    0    0  \n",
       "3         NaN    0    0  \n",
       "4         NaN    0    0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the data from CSV\n",
    "\n",
    "import pandas\n",
    "\n",
    "allComments = pandas.read_csv(\"./data/comments-labelled.csv\")\n",
    "allComments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>labelled_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our national monuments are a national treasure...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.We do not want National Monument protection ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The monuments must be preserved. the precedent...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My name is Ryan Erik Benally and I'm from Mont...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>all protections and preservations for the enti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment Sentiment labelled_by\n",
       "0  Our national monuments are a national treasure...       NaN         NaN\n",
       "1  1.We do not want National Monument protection ...       NaN         NaN\n",
       "2  The monuments must be preserved. the precedent...       NaN         NaN\n",
       "3  My name is Ryan Erik Benally and I'm from Mont...       NaN         NaN\n",
       "4  all protections and preservations for the enti...       NaN         NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leave out unused columns \n",
    "\n",
    "allComments.drop(allComments.columns[[0,1,2,3,4,5,7,8,11,12]], axis=1, inplace=True) \n",
    "allComments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split text into sentences\n",
    "# Ref: https://stackoverflow.com/a/31505798\n",
    "\n",
    "import re\n",
    "\n",
    "caps = \"([A-Z])\"\n",
    "digits = \"([0-9])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\n",
    "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "websites = \"[.](com|net|org|io|gov)\"\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "    text = re.sub(\"\\s\" + caps + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(digits + \"[.]\" + digits,\"\\\\1<prd>\\\\2\",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(caps + \"[.]\" + caps + \"[.]\" + caps + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(caps + \"[.]\" + caps + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + caps + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = [s.strip() for s in sentences if len(s.strip())>1]\n",
    "    return sentences\n",
    "\n",
    "\n",
    "sentences = allComments['comment'].map(lambda x: split_into_sentences(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique sentences: 508294\n"
     ]
    }
   ],
   "source": [
    "# Build a sentence-frequency dictionary from text\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "frequency = defaultdict(int)\n",
    "for sent_list in sentences:\n",
    "    for sent in sent_list:\n",
    "        frequency[sent] += 1\n",
    "\n",
    "uniqueSentences = list(frequency.keys())\n",
    "print(\"Number of unique sentences:\", len(uniqueSentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 common sentences:\n",
      "[('He and all fifteen subsequent presidents--of both parties--have recognized the need and value of protecting these public lands with the Antiquities Act.', 23034), ('These monuments are a legacy of Teddy Roosevelt.', 23033), ('Reversing any of these designations would be a tragic mistake with harmful consequences for all that depend on our magnificent public lands.', 23027), (\"I urge you to uphold Roosevelt's legacy and maintain these monuments for current and future generations.\", 22996), ('The national monuments created in the past twenty years have protected vital bird habitat, helped safeguard our heritage, and benefited communities across the country.', 22950), ('From the buttes of Bears Ears that support birds like the Golden Eagle, to the underwater canyons of the Northeast Canyons and Seamounts National Monument that support a critical ecosystem for Atlantic Puffins, to the rocky peaks of the Organ Mountains-Desert Peaks National Monument, the shrub-steppe habitat of Hanford Reach National Monument in Washington, and out to the pristine Pacific waters of the Papahanaumokuakea National Monument, all of these lands and waters are indispensable to birds and other wildlife.', 22900), ('Dear Secretary Ryan Zinke,  As a supporter of bird conservation and our public lands, I strongly urge you to protect all national monuments under review, and to reject any changes to these iconic landscapes.', 22208), ('Our community is invested in ensuring that these important landscapes will remain under long-term protection.', 5022), ('American sportsmen and women support judicious use of the Antiquities Act to permanently conserve important lands and waters, safeguard fish and wildlife habitat, and secure public hunting and fishing opportunities.', 5001), ('Presidents of both parties have issued monument declarations and consistently respected those issued by their predecessors.', 4949)]\n"
     ]
    }
   ],
   "source": [
    "# (Optional) Sort the sentence-frequency dictionary by frequency and write to CSV\n",
    "\n",
    "import operator\n",
    "import csv\n",
    "\n",
    "sorted_frequency_list = sorted(frequency.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print(\"Top 10 common sentences:\")\n",
    "print(sorted_frequency_list[:10])\n",
    "\n",
    "with open('sentence_frequency.csv', 'w') as csv_output:\n",
    "    fieldnames = ['frequency', 'sentence']\n",
    "    writer = csv.DictWriter(csv_output, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for item in sorted_frequency_list:\n",
    "        writer.writerow({'frequency': item[1], 'sentence': item[0]})\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tokenize the corpus (all unique sentences) and create a token stream for training a collocation detector\n",
    "\n",
    "import gensim\n",
    "\n",
    "def tokenize(text, minimumLength=3):\n",
    "    return gensim.utils.simple_preprocess(text, deacc=True, min_len=minimumLength)\n",
    "    \n",
    "tokenized_sentences = []\n",
    "for line in uniqueSentences:\n",
    "    tokenized_sentences.append(tokenize(line, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hsinyuyao/anaconda/lib/python3.5/site-packages/gensim/models/phrases.py:274: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['our',\n",
       " 'national_monuments',\n",
       " 'are',\n",
       " 'national_treasure',\n",
       " 'for',\n",
       " 'all',\n",
       " 'enjoy']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a collocation detector\n",
    "\n",
    "from gensim.models import Phrases\n",
    "\n",
    "bigram = Phrases(tokenized_sentences, min_count=1, threshold=2)\n",
    "test = tokenize(\"Our national monuments are a national treasure for all to enjoy\", 3)\n",
    "bigram[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hsinyuyao/anaconda/lib/python3.5/site-packages/gensim/models/phrases.py:274: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['keep', 'lands', 'public', 'shrink', 'size', 'listed', 'monuments'],\n",
       " ['david_brower',\n",
       "  'regretted',\n",
       "  'decision',\n",
       "  'compromise',\n",
       "  'move',\n",
       "  'dam',\n",
       "  'location',\n",
       "  'sierra_club',\n",
       "  'lost',\n",
       "  'president',\n",
       "  'politic',\n",
       "  'land',\n",
       "  'preservation',\n",
       "  'changed'],\n",
       " ['particular',\n",
       "  'regularly_visited',\n",
       "  'san_gabriel',\n",
       "  'mountains_california',\n",
       "  'resident']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess text through stopword removal, collocation detection and lemmatization\n",
    "\n",
    "from gensim.utils import lemmatize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(tokenized_text):\n",
    "    \n",
    "    text = [[word for word in line if word not in stopwords] for line in tokenized_text]\n",
    "    text = [bigram[line] for line in text]\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = [[word for word in lemmatizer.lemmatize(' '.join(line), pos='v').split()] for line in text]\n",
    "    return text\n",
    "\n",
    "\n",
    "preprocess_text(tokenized_sentences[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hsinyuyao/anaconda/lib/python3.5/site-packages/gensim/models/phrases.py:274: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>labelled_by</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our national monuments are a national treasure...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[national_monuments, national_treasure, enjoy,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.We do not want National Monument protection ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[want, national_monument, protection_removed, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The monuments must be preserved. the precedent...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[monuments, must_preserved, precedent_removing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My name is Ryan Erik Benally and I'm from Mont...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[name, ryan, erik, benally, montezuma_creek, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>all protections and preservations for the enti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[protections, preservations, entire_country, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment Sentiment labelled_by  \\\n",
       "0  Our national monuments are a national treasure...       NaN         NaN   \n",
       "1  1.We do not want National Monument protection ...       NaN         NaN   \n",
       "2  The monuments must be preserved. the precedent...       NaN         NaN   \n",
       "3  My name is Ryan Erik Benally and I'm from Mont...       NaN         NaN   \n",
       "4  all protections and preservations for the enti...       NaN         NaN   \n",
       "\n",
       "                                               token  \n",
       "0  [national_monuments, national_treasure, enjoy,...  \n",
       "1  [want, national_monument, protection_removed, ...  \n",
       "2  [monuments, must_preserved, precedent_removing...  \n",
       "3  [name, ryan, erik, benally, montezuma_creek, u...  \n",
       "4  [protections, preservations, entire_country, a...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize and preprocess individual comments \n",
    "\n",
    "def text_to_token(text):\n",
    "    tokens = [tokenize(sent) for sent in split_into_sentences(text)]\n",
    "    flat_list = [item for sublist in preprocess_text(tokens) for item in sublist]\n",
    "    return flat_list\n",
    "        \n",
    "allComments['token'] = allComments['comment'].map(lambda text: text_to_token(text))\n",
    "allComments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(139698 unique tokens: ['favoribly', 'customs', 'number_plant', 'grasslands_wildlife', 'either_proposition']...)\n"
     ]
    }
   ],
   "source": [
    "# Finalize the corpus and dictionary for topic modeling \n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim import corpora\n",
    "\n",
    "dictionary = Dictionary(allComments.token)\n",
    "dictionary.compactify()\n",
    "corpus = [dictionary.doc2bow(comment) for comment in allComments.token]\n",
    "\n",
    "corpora.MmCorpus.serialize('./data/monument.mm', corpus)  # store the corpus to disk\n",
    "dictionary.save('./data/monument.dict')  # store the dictionary\n",
    "\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71663, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>labelled_by</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52131</th>\n",
       "      <td>I am writing you in support of our national mo...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>template</td>\n",
       "      <td>writing_support national_monuments comment rev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11021</th>\n",
       "      <td>Dear Secretary Ryan Zinke,\\n\\nAs a supporter o...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>template</td>\n",
       "      <td>dear_secretary ryan_zinke supporter_bird conse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76034</th>\n",
       "      <td>Dear Secretary Ryan Zinke,\\nBears Ears Nationa...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>template</td>\n",
       "      <td>dear_secretary ryan_zinke bears_ears national_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85226</th>\n",
       "      <td>Our national monuments and public lands and wa...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>template</td>\n",
       "      <td>national_monuments public_lands waters_help de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31573</th>\n",
       "      <td>Katahdin Woods National Monument is a gem. How...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>hand</td>\n",
       "      <td>katahdin_woods national_monument gem even_cons...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment Sentiment  \\\n",
       "52131  I am writing you in support of our national mo...  Positive   \n",
       "11021  Dear Secretary Ryan Zinke,\\n\\nAs a supporter o...  Positive   \n",
       "76034  Dear Secretary Ryan Zinke,\\nBears Ears Nationa...  Positive   \n",
       "85226  Our national monuments and public lands and wa...  Positive   \n",
       "31573  Katahdin Woods National Monument is a gem. How...  Positive   \n",
       "\n",
       "      labelled_by                                              token  \n",
       "52131    template  writing_support national_monuments comment rev...  \n",
       "11021    template  dear_secretary ryan_zinke supporter_bird conse...  \n",
       "76034    template  dear_secretary ryan_zinke bears_ears national_...  \n",
       "85226    template  national_monuments public_lands waters_help de...  \n",
       "31573        hand  katahdin_woods national_monument gem even_cons...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For training the classifer, output labelled instances as training data\n",
    "\n",
    "allComments['token'] = allComments['token'].map(lambda x: \" \".join(x))\n",
    "labelledComments = allComments.dropna()\n",
    "labelledComments.to_csv('./data/comments-for-train.csv', index=False)\n",
    "\n",
    "print(labelledComments.shape)\n",
    "labelledComments.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74646, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>labelled_by</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63469</th>\n",
       "      <td>STOP! STOP! STOP! This is just another example...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>classifier</td>\n",
       "      <td>stop stop stop another_example greed public_op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121238</th>\n",
       "      <td>Please don't carelessly remove the designation...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>classifier</td>\n",
       "      <td>please carelessly remove designation lands are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64976</th>\n",
       "      <td>Trump is obsessed with killing every accomplis...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>classifier</td>\n",
       "      <td>trump obsessed killing every accomplishment pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25214</th>\n",
       "      <td>The fact that this 'review' is even happening ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>classifier</td>\n",
       "      <td>fact review even_happening demonstrates short_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100975</th>\n",
       "      <td>Grand Staircase, Bears Ears and other national...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>classifier</td>\n",
       "      <td>grand_staircase bears_ears national_monuments ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  comment Sentiment  \\\n",
       "63469   STOP! STOP! STOP! This is just another example...       NaN   \n",
       "121238  Please don't carelessly remove the designation...       NaN   \n",
       "64976   Trump is obsessed with killing every accomplis...       NaN   \n",
       "25214   The fact that this 'review' is even happening ...       NaN   \n",
       "100975  Grand Staircase, Bears Ears and other national...       NaN   \n",
       "\n",
       "       labelled_by                                              token  \n",
       "63469   classifier  stop stop stop another_example greed public_op...  \n",
       "121238  classifier  please carelessly remove designation lands are...  \n",
       "64976   classifier  trump obsessed killing every accomplishment pr...  \n",
       "25214   classifier  fact review even_happening demonstrates short_...  \n",
       "100975  classifier  grand_staircase bears_ears national_monuments ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare unlabelled comments for our classifier to label \n",
    "\n",
    "unlabelledComments = allComments[allComments['Sentiment'].notnull() == False]\n",
    "unlabelledComments = unlabelledComments[unlabelledComments.token != '']\n",
    "unlabelledComments.labelled_by = 'classifier'\n",
    "unlabelledComments.to_csv('./data/comments-to-label.csv', index=False) \n",
    "\n",
    "print(unlabelledComments.shape)\n",
    "unlabelledComments.sample(5)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
