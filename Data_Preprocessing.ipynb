{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook:\n",
    "- explores the dataset to gain a basic understanding\n",
    "- filters out unwanted instances e.g. empty or duplicate texts\n",
    "- samples 2000 instances to label manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the dataset\n",
    "- Obtain basic statistics and characteristics of the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# comments scraped: 151631\n",
      "# comments with duplicates removed: 116287\n"
     ]
    }
   ],
   "source": [
    "# Load in the data from CSV\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "allComments = pd.read_csv(\"data/comments.csv\", usecols=['document_id', 'comment', 'has_attachments'])\n",
    "print(\"# comments scraped:\", allComments.shape[0])\n",
    "\n",
    "allComments = allComments.drop_duplicates(subset = ['comment'])\n",
    "print(\"# comments with duplicates removed:\", allComments.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20499     Please Write Your Comment Here: STOP EVERYTHIN...\n",
       "5965      Dear Secretary Ryan Zinke,\\nProtected public l...\n",
       "141836    Dear Secretary Ryan Zinke,\\nPlease keep Bears ...\n",
       "43194     Dear Secretary Ryan Zinke,\\nOur public lands a...\n",
       "25033     I'm disgusted with the executive order 13792. ...\n",
       "64154     Please leave these National Monuments alone, u...\n",
       "132572    I am writing in response to the Department of ...\n",
       "122380    Dear Secretary Ryan Zinke,\\n\\nAs a supporter o...\n",
       "57715     Dear Secretary Ryan Zinke,\\n\\nOur national mon...\n",
       "85423     Dear Secretary Ryan Zinke,\\n\\nI am a frequent ...\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample 10 comments to veiw \n",
    "\n",
    "allComments.sample(10).comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split texts into sentences\n",
    "# Ref: https://stackoverflow.com/a/31505798\n",
    "\n",
    "import re\n",
    "\n",
    "caps = \"([A-Z])\"\n",
    "digits = \"([0-9])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\n",
    "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "websites = \"[.](com|net|org|io|gov)\"\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    '''\n",
    "    Function to break text (astring) into sentences (a list of strings).\n",
    "    '''\n",
    "    \n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "    text = re.sub(\"\\s\" + caps + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(digits + \"[.]\" + digits,\"\\\\1<prd>\\\\2\",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(caps + \"[.]\" + caps + \"[.]\" + caps + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(caps + \"[.]\" + caps + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + caps + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = [s.strip() for s in sentences if len(s.strip())>1]\n",
    "    return sentences\n",
    "\n",
    "allComments['sentences'] = allComments['comment'].map(lambda x: split_into_sentences(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sentences: 827303\n",
      "# unique sentences: 520456\n",
      "\n",
      "10 most common sentences:\n",
      "1 He and all fifteen subsequent presidents--of both ... 19434\n",
      "2 These monuments are a legacy of Teddy Roosevelt.... 19433\n",
      "3 Reversing any of these designations would be a tra... 19415\n",
      "4 I urge you to uphold Roosevelt's legacy and mainta... 19397\n",
      "5 The national monuments created in the past twenty ... 19338\n",
      "6 From the buttes of Bears Ears that support birds l... 19302\n",
      "7 Dear Secretary Ryan Zinke,  As a supporter of bird... 18607\n",
      "8 Thank you.... 3757\n",
      "9 I strongly urge you to oppose any efforts to elimi... 3730\n",
      "10 I am firmly opposed to any effort to revoke or dim... 3599\n"
     ]
    }
   ],
   "source": [
    "# Output some statistics about the corpus\n",
    "\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "\n",
    "sentences = [s for sublist in allComments['sentences'] for s in sublist]\n",
    "print(\"# sentences:\", len(sentences))\n",
    "\n",
    "frequency = defaultdict(int)\n",
    "for sent_list in allComments['sentences']:\n",
    "    for sent in sent_list:\n",
    "        frequency[sent] += 1\n",
    "\n",
    "uniqueSentences = list(frequency.keys())\n",
    "print(\"# unique sentences:\", len(uniqueSentences))\n",
    "print()\n",
    "\n",
    "sorted_frequency_list = sorted(frequency.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print(\"10 most common sentences:\")\n",
    "for index, row in enumerate(sorted_frequency_list[:10]):\n",
    "    print(index+1, row[0][:50]+\"...\", row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the sample comments and sentence frequencies, it is clear that a large portion of comments were submitted in templates. We need to identify those template comments so that when we sample comments to label (for model training) we do not have duplicate or overly similar text. We want to prevent words used in templates from biasing our feature weights. One simple way to filter out template comments is compare the first two sentences in the text and then remove comments whose starting two sentences have been seen in previous comments. The reasoning is that two posters are unlikely to have written the same words if they didn't come from a template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out comments\n",
    "- Remove empty comments\n",
    "- Remove comments with attachments\n",
    "- Remove duplicate and template comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# comments with empty comments removed: 116281\n"
     ]
    }
   ],
   "source": [
    "# Remove empty comments whose sentence count is zero\n",
    "\n",
    "allComments = allComments[allComments['sentences'].map(len) != 0]\n",
    "print(\"# comments with empty comments removed:\", allComments.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# comments with no content comments removed: 115664\n"
     ]
    }
   ],
   "source": [
    "# Remove empty comments whose text contains only the official template lines\n",
    "# i.e. \"Dear Secretary Ryan Zinke,\" and/or \"Leave your personal comment here...\"\n",
    "\n",
    "def hasContent(sentences):\n",
    "    if sentences[0].find('Leave your personal comment here') != -1 \\\n",
    "    or (len(sentences) == 2 and len(sentences[0]) < 30 and \\\n",
    "        sentences[0].find('Dear Secretary Ryan Zinke,') != -1):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "allComments = allComments[allComments['sentences'].map(hasContent)]\n",
    "print(\"# comments with no content comments removed:\", allComments.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# comments without attachments: 114373\n"
     ]
    }
   ],
   "source": [
    "# Remove comments with attachments\n",
    "\n",
    "allComments = allComments[allComments['has_attachments'] == False]\n",
    "print(\"# comments without attachments:\", allComments.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# rather unique comments: 79314\n"
     ]
    }
   ],
   "source": [
    "# Considering that there are minor variations within the same template (e.g. punctuations and spaces), \n",
    "# use gensim's built-in function simple_preprocess() to lowercase and tokenize sentences.\n",
    "# Then drop duplicate comments whose first two sentences are the same.\n",
    "\n",
    "import gensim\n",
    "\n",
    "def tokenize(text, minLength=3):\n",
    "    return gensim.utils.simple_preprocess(text, deacc=True, min_len=minLength)\n",
    "\n",
    "allComments['first_two_sents'] = allComments['sentences'].map(lambda x: \" \".join([\" \".join(tokenize(sent)) for sent in x[:2]]))\n",
    "uniqueComments = allComments.drop_duplicates(subset=['first_two_sents'])\n",
    "print(\"# rather unique comments:\", uniqueComments.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38159</th>\n",
       "      <td>DOI-2017-0002-134730</td>\n",
       "      <td>To Whom It May Concern:\\n\\nThe Grand Staircase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127110</th>\n",
       "      <td>DOI-2017-0002-77680</td>\n",
       "      <td>Secretary Zinke,\\nStanding before a Giant Sequ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75589</th>\n",
       "      <td>DOI-2017-0002-30809</td>\n",
       "      <td>Dear Secretary Ryan Zinke,\\n\\nAs a photographe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43237</th>\n",
       "      <td>DOI-2017-0002-13995</td>\n",
       "      <td>I would like to voice my opinion that the monu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136271</th>\n",
       "      <td>DOI-2017-0002-86016</td>\n",
       "      <td>Dear Secretary Zinke,\\n\\nConsider this:\\nThe m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59758</th>\n",
       "      <td>DOI-2017-0002-16403</td>\n",
       "      <td>I am opposed to opening our national monuments...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>DOI-2017-0002-0048</td>\n",
       "      <td>National monuments are great for the economy. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92862</th>\n",
       "      <td>DOI-2017-0002-4652</td>\n",
       "      <td>Leave our national monuments and open spaces u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42769</th>\n",
       "      <td>DOI-2017-0002-139333</td>\n",
       "      <td>Dear Secretary Ryan Zinke,\\n\\nOur national mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19571</th>\n",
       "      <td>DOI-2017-0002-116877</td>\n",
       "      <td>Please continue protecting the national monume...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 document_id  \\\n",
       "38159   DOI-2017-0002-134730   \n",
       "127110   DOI-2017-0002-77680   \n",
       "75589    DOI-2017-0002-30809   \n",
       "43237    DOI-2017-0002-13995   \n",
       "136271   DOI-2017-0002-86016   \n",
       "59758    DOI-2017-0002-16403   \n",
       "46        DOI-2017-0002-0048   \n",
       "92862     DOI-2017-0002-4652   \n",
       "42769   DOI-2017-0002-139333   \n",
       "19571   DOI-2017-0002-116877   \n",
       "\n",
       "                                                  comment  \n",
       "38159   To Whom It May Concern:\\n\\nThe Grand Staircase...  \n",
       "127110  Secretary Zinke,\\nStanding before a Giant Sequ...  \n",
       "75589   Dear Secretary Ryan Zinke,\\n\\nAs a photographe...  \n",
       "43237   I would like to voice my opinion that the monu...  \n",
       "136271  Dear Secretary Zinke,\\n\\nConsider this:\\nThe m...  \n",
       "59758   I am opposed to opening our national monuments...  \n",
       "46      National monuments are great for the economy. ...  \n",
       "92862   Leave our national monuments and open spaces u...  \n",
       "42769   Dear Secretary Ryan Zinke,\\n\\nOur national mon...  \n",
       "19571   Please continue protecting the national monume...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample a few comments for viewing\n",
    "\n",
    "uniqueComments[['document_id', 'comment']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample data \n",
    "- randomly sample 2000 instances\n",
    "- output to file for manual labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output 2000 comments to CSV for manual labelling\n",
    "\n",
    "comments_to_label = uniqueComments[['document_id', 'comment']].sample(2000)\n",
    "comments_to_label.to_csv('data/comments-to-label.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
